name: PR Evaluator

on:
  pull_request:
    types: [opened, synchronize]

permissions:
  contents: write
  pull-requests: write
  issues: write

jobs:
  evaluate:
    if: >
      !contains(github.event.pull_request.labels.*.name, 'skip-review') &&
      !contains(github.event.pull_request.labels.*.name, 'needs-human')
    runs-on: ubuntu-latest
    timeout-minutes: 15
    concurrency:
      group: pr-eval-${{ github.event.pull_request.number }}
      cancel-in-progress: true
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.ref }}
          token: ${{ secrets.PAT }}

      - name: Collect PR context
        id: context
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.PAT }}
          script: |
            const fs = require('fs');
            const pr = context.payload.pull_request;

            fs.writeFileSync('/tmp/pr-title.txt', pr.title);
            fs.writeFileSync('/tmp/pr-body.txt', pr.body || '');
            fs.writeFileSync('/tmp/pr-number.txt', String(pr.number));
            fs.writeFileSync('/tmp/pr-branch.txt', pr.head.ref);

            // Get existing review comments to understand iteration history
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: pr.number,
              per_page: 50
            });

            const reviewComments = comments
              .filter(c => c.body.includes('## PR Evaluation'))
              .map(c => c.body);

            const iterationCount = reviewComments.length;
            fs.writeFileSync('/tmp/iteration-count.txt', String(iterationCount));
            fs.writeFileSync('/tmp/review-history.txt',
              reviewComments.length > 0
                ? reviewComments.slice(-2).join('\n---\n')
                : 'No previous reviews.'
            );

            // Check for revision labels to track how many fix cycles we've done
            const labels = pr.labels.map(l => l.name);
            const revisionLabels = labels.filter(l => l.startsWith('revision-'));
            const currentRevision = revisionLabels.length;
            fs.writeFileSync('/tmp/current-revision.txt', String(currentRevision));

            core.setOutput('iteration_count', String(iterationCount));
            core.setOutput('current_revision', String(currentRevision));

      - name: Escalate if too many iterations
        if: steps.context.outputs.current_revision >= 3
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.PAT }}
          script: |
            const pr = context.payload.pull_request;
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: pr.number,
              labels: ['needs-human']
            });
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: pr.number,
              body: '## PR Evaluation\n\n**Escalated to human review.** This PR has gone through 3 revision cycles without passing automated review. A human engineer should evaluate the approach and provide guidance.\n\ncc @stephanbirkeland'
            });

      - uses: astral-sh/setup-uv@v4
        if: steps.context.outputs.current_revision < 3
        with:
          version: "latest"

      - uses: actions/setup-python@v5
        if: steps.context.outputs.current_revision < 3
        with:
          python-version: "3.12"

      - name: Install dependencies
        if: steps.context.outputs.current_revision < 3
        run: uv sync --dev

      - name: Run CI checks locally
        if: steps.context.outputs.current_revision < 3
        id: local-ci
        run: |
          set +e
          uv run ruff check src/ > /tmp/lint-output.txt 2>&1
          LINT_EXIT=$?
          uv run mypy src/ > /tmp/type-output.txt 2>&1
          TYPE_EXIT=$?
          uv run pytest --tb=short > /tmp/test-output.txt 2>&1
          TEST_EXIT=$?
          set -e

          if [ $LINT_EXIT -ne 0 ] || [ $TYPE_EXIT -ne 0 ] || [ $TEST_EXIT -ne 0 ]; then
            echo "ci_pass=false" >> "$GITHUB_OUTPUT"
            echo "CI failed: lint=$LINT_EXIT type=$TYPE_EXIT test=$TEST_EXIT"
          else
            echo "ci_pass=true" >> "$GITHUB_OUTPUT"
            echo "All CI checks pass locally"
          fi

      - name: Get PR diff
        if: steps.context.outputs.current_revision < 3
        run: |
          git diff origin/main...HEAD > /tmp/pr-diff.txt
          git diff --stat origin/main...HEAD > /tmp/pr-stat.txt

      - name: Build review prompt
        if: steps.context.outputs.current_revision < 3
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const read = (f) => { try { return fs.readFileSync(f, 'utf8'); } catch { return ''; } };

            const prompt = `You are a **Senior Staff Engineer** acting as an automated PR reviewer for AnimeForge.
            Your role is to evaluate PRs with the rigor of a tech lead at a top-tier company.
            You make a final APPROVE or REQUEST_CHANGES verdict — no middle ground.

            ## PR #${read('/tmp/pr-number.txt').trim()}: ${read('/tmp/pr-title.txt').trim()}

            ${read('/tmp/pr-body.txt')}

            ## File Changes
            ${read('/tmp/pr-stat.txt')}

            ## Diff
            ${read('/tmp/pr-diff.txt')}

            ## CI Results (ran locally)
            CI passed: ${{ steps.local-ci.outputs.ci_pass }}

            ### Lint output
            ${read('/tmp/lint-output.txt')}

            ### Type check output
            ${read('/tmp/type-output.txt')}

            ### Test output
            ${read('/tmp/test-output.txt')}

            ## Previous Review History (iteration ${read('/tmp/iteration-count.txt').trim()}, revision ${read('/tmp/current-revision.txt').trim()})
            ${read('/tmp/review-history.txt')}

            ## Your Task

            First, read CLAUDE.md to understand project conventions.

            Then evaluate this PR on these criteria (all must pass for approval):

            ### 1. Correctness
            - Does the code do what the PR claims?
            - Are there logic errors, off-by-one errors, or race conditions?
            - Are edge cases handled?

            ### 2. Code Quality
            - Does it follow the project's conventions (see CLAUDE.md)?
            - Is the code clean, readable, and maintainable?
            - Are there any code smells (god functions, deep nesting, magic numbers)?

            ### 3. Testing
            - Are there tests for new functionality?
            - Do tests cover edge cases and error paths?
            - Are tests meaningful (not just testing that Python works)?

            ### 4. Security
            - Any injection vulnerabilities, hardcoded secrets, or unsafe operations?
            - Is user input properly validated?

            ### 5. CI Status
            - All lint, type checking, and tests must pass

            ### 6. Scope
            - Are changes focused on what the PR describes?
            - No unrelated refactoring or feature creep?

            ## Output Format

            You MUST output EXACTLY this format:

            VERDICT: APPROVE or REQUEST_CHANGES

            ## Review Summary
            (1-2 sentences on what this PR does)

            ## Evaluation
            | Criteria | Status | Notes |
            |----------|--------|-------|
            | Correctness | PASS/FAIL | brief note |
            | Code Quality | PASS/FAIL | brief note |
            | Testing | PASS/FAIL | brief note |
            | Security | PASS/FAIL | brief note |
            | CI Status | PASS/FAIL | brief note |
            | Scope | PASS/FAIL | brief note |

            ## Issues Found
            (List specific issues if REQUEST_CHANGES, or "None" if APPROVE)
            For each issue:
            - **File:Line** — Description of the problem
            - **Suggested fix** — How to fix it

            ## Action Items
            (Numbered list of what needs to change before re-review, or "Ready to merge" if APPROVE)

            IMPORTANT:
            - Be strict but fair. Don't nitpick style if the code follows project conventions.
            - If CI fails, that's an automatic REQUEST_CHANGES.
            - If this is a revision (iteration > 0), focus on whether previous issues were addressed.
            - Only APPROVE if ALL criteria pass. Any FAIL = REQUEST_CHANGES.`;

            fs.writeFileSync('/tmp/review-prompt.txt', prompt);

      - name: Install Claude Code
        if: steps.context.outputs.current_revision < 3
        run: npm install -g @anthropic-ai/claude-code

      - name: Senior Engineer Review
        if: steps.context.outputs.current_revision < 3
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          claude --model claude-sonnet-4-6 --max-turns 10 --print --dangerously-skip-permissions -p "$(cat /tmp/review-prompt.txt)" > /tmp/review-output.txt

      - name: Parse verdict and act
        if: steps.context.outputs.current_revision < 3
        id: verdict
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.PAT }}
          script: |
            const fs = require('fs');
            const pr = context.payload.pull_request;

            let reviewOutput = 'Review completed — check workflow logs.';
            try {
              reviewOutput = fs.readFileSync('/tmp/review-output.txt', 'utf8').trim();
            } catch (e) {
              console.log('Could not read review output:', e.message);
            }

            // Parse verdict
            const verdictMatch = reviewOutput.match(/VERDICT:\s*(APPROVE|REQUEST_CHANGES)/);
            const verdict = verdictMatch ? verdictMatch[1] : 'REQUEST_CHANGES';
            core.setOutput('verdict', verdict);

            // Post the review comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: pr.number,
              body: `## PR Evaluation (Automated Senior Review)\n\n${reviewOutput}`
            });

            if (verdict === 'APPROVE') {
              // Submit an approving review
              await github.rest.pulls.createReview({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: pr.number,
                event: 'APPROVE',
                body: 'Automated senior review: All criteria passed. Approved for merge.'
              });

              // Add approved label
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: pr.number,
                labels: ['review-approved']
              });

              console.log(`PR #${pr.number} APPROVED`);
            } else {
              // Submit a changes-requested review
              await github.rest.pulls.createReview({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: pr.number,
                event: 'REQUEST_CHANGES',
                body: 'Automated senior review: Issues found that need to be addressed.'
              });

              // Track revision count
              const revision = parseInt(fs.readFileSync('/tmp/current-revision.txt', 'utf8').trim()) + 1;
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: pr.number,
                labels: [`revision-${revision}`]
              });

              console.log(`PR #${pr.number} REQUEST_CHANGES (revision ${revision})`);
            }

      - name: Auto-merge if approved
        if: >
          steps.context.outputs.current_revision < 3 &&
          steps.verdict.outputs.verdict == 'APPROVE'
        env:
          GH_TOKEN: ${{ secrets.PAT }}
        run: |
          PR_NUM=$(cat /tmp/pr-number.txt)
          echo "Enabling auto-merge for PR #${PR_NUM}"
          gh pr merge "$PR_NUM" --auto --squash

      - name: Build fix prompt
        if: >
          steps.context.outputs.current_revision < 3 &&
          steps.verdict.outputs.verdict == 'REQUEST_CHANGES' &&
          startsWith(github.event.pull_request.head.ref, 'claude/')
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const read = (f) => { try { return fs.readFileSync(f, 'utf8'); } catch { return ''; } };
            const prNum = read('/tmp/pr-number.txt').trim();
            const review = read('/tmp/review-output.txt');

            const prompt = `A senior engineer has reviewed this PR and requested changes.
            You need to address ALL the issues identified in the review.

            ## Review Feedback

            ${review}

            ## Instructions

            1. Read CLAUDE.md to understand project conventions
            2. Address EVERY issue listed in the "Issues Found" and "Action Items" sections
            3. Run \`uv run ruff check src/\` and fix any lint errors
            4. Run \`uv run mypy src/\` and fix any type errors
            5. Run \`uv run pytest\` and fix any test failures
            6. Commit your changes with: "fix: address review feedback for PR #${prNum}"
            7. Do NOT push — the workflow handles that

            Important:
            - Fix ONLY what was flagged in the review
            - Do not refactor unrelated code
            - Make sure ALL action items are addressed`;

            fs.writeFileSync('/tmp/fix-prompt.txt', prompt);

      - name: Fix issues if changes requested on claude branch
        if: >
          steps.context.outputs.current_revision < 3 &&
          steps.verdict.outputs.verdict == 'REQUEST_CHANGES' &&
          startsWith(github.event.pull_request.head.ref, 'claude/')
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          GH_TOKEN: ${{ secrets.PAT }}
        run: |
          PR_NUM=$(cat /tmp/pr-number.txt)
          BRANCH=$(cat /tmp/pr-branch.txt)

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          claude --model claude-sonnet-4-6 --max-turns 20 --dangerously-skip-permissions -p "$(cat /tmp/fix-prompt.txt)"

          # Push fixes if any changes were made
          if ! git diff --quiet HEAD; then
            git push origin "${BRANCH}"
            gh pr comment "$PR_NUM" --body "Revision pushed — addressing review feedback. Awaiting re-evaluation."
          else
            echo "No changes made — may need human intervention"
            gh pr comment "$PR_NUM" --body "Automated fix attempt produced no changes. This may need human review."
          fi
